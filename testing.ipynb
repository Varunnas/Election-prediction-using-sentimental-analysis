{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4yq3PPnMhWh"
      },
      "source": [
        "### **TESTING MODEL WITH DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikjp36nCML85"
      },
      "source": [
        "We will use the Bir-directional LSTM method to test data because when the models were compared based on the Test loss and Test Accuracy. The Bidirectional LSTM performed slightly better than the GloVe model. . We use the Bidirectional LSTM to make the predictions for the tweets that will be used to infer election results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i34WCyLxM06G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "T99t8wtiMhKY"
      },
      "outputs": [],
      "source": [
        "congress_test = pd.read_csv('congress_test.csv')\n",
        "bjp_test = pd.read_csv('bjp_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_ebXbsm9NAoC"
      },
      "outputs": [],
      "source": [
        "congress_test =congress_test[:2000]\n",
        "bjp_test = bjp_test[0:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HuYdYnEGNCh2"
      },
      "outputs": [],
      "source": [
        "def tweet_to_words( raw_review ):\n",
        "    # Remove non-letters\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", str(raw_review))\n",
        "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', str(letters_only)) # remove URLs\n",
        "    tweet = re.sub('RT', ' ', str(tweet))\n",
        "\n",
        "    #Convert to lower case, split into individual words\n",
        "    tweet = letters_only.lower().split()\n",
        "\n",
        "\n",
        "\n",
        "    return( \" \".join(tweet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nPoaniGXNG30"
      },
      "outputs": [],
      "source": [
        "# Get the number of Tweets based on the dataframe column size\n",
        "num_tweets = 2000\n",
        "\n",
        "# Initialize an empty list to hold the clean reviews\n",
        "\n",
        "\n",
        "# Loop over each tweet; create an index i that goes from 0 to the length\n",
        "# of the tweet list\n",
        "def clean_test(dataframe):\n",
        "    clean_train_tweets = []\n",
        "    for i in range( 0, num_tweets ):\n",
        "        # Call function for each one, and add the result to the list of\n",
        "        clean_train_tweets.append( tweet_to_words(dataframe[i]))\n",
        "    return clean_train_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vePL49MHNJ5E"
      },
      "outputs": [],
      "source": [
        "congress_inputs = clean_test(congress_test['clean_text'])\n",
        "bjp_inputs = clean_test(bjp_test['clean_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pmff_mU7NKmo"
      },
      "outputs": [],
      "source": [
        "def tokenze_data(data_inputs):\n",
        "        tokenizer = Tokenizer(nb_words=2000)\n",
        "        tokenizer.fit_on_texts(data_inputs)\n",
        "        sequences = tokenizer.texts_to_sequences(data_inputs)\n",
        "\n",
        "        word_index = tokenizer.word_index\n",
        "        print('Found %s unique tokens.' % len(word_index))\n",
        "        max_len = 200\n",
        "        data = pad_sequences(sequences, max_len)\n",
        "        print('Shape of data tensor:', data.shape)\n",
        "        indices = np.arange(data.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        data = data[indices]\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05VyL5TvNMZh",
        "outputId": "ed729517-b9ed-4964-ca83-516b274dea1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3459 unique tokens.\n",
            "Shape of data tensor: (2000, 200)\n",
            "Found 2588 unique tokens.\n",
            "Shape of data tensor: (2000, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/text.py:98: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "congress_inputs = tokenze_data(congress_inputs)\n",
        "bjp_inputs = tokenze_data(bjp_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOObUwQ2NQ_P",
        "outputId": "df90dd42-5efc-4760-fea2-593c9d600e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ],
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# load json and create model\n",
        "with open(\"/content/Model_Bidir_LSTM.json\", 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/Weights_bidir_LSTM.weights.h5\")\n",
        "print(\"Loaded model from disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp9mYZkmNwcY",
        "outputId": "5869e728-759d-4cfa-ae94-615cf827e396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step\n"
          ]
        }
      ],
      "source": [
        "congress_prediction = loaded_model.predict(congress_inputs)\n",
        "bjp_prediction = loaded_model.predict(bjp_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "f_j8m_vLN3h3"
      },
      "outputs": [],
      "source": [
        "congress_pred = (congress_prediction>0.5)\n",
        "bjp_pred = (bjp_prediction>0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "15bUbRW6Rvxi"
      },
      "outputs": [],
      "source": [
        "def get_predictions(party_pred):\n",
        "    x = 0\n",
        "    for i in party_pred:\n",
        "        if(i[1]==True):\n",
        "            x+=1\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxQM7YMcRxrh",
        "outputId": "92151d61-906c-4fbc-a7ca-6c97a70b2d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Congress Positive Tweets: 394\n",
            "BJP Positive Tweets: 887\n"
          ]
        }
      ],
      "source": [
        "congress_numbers = get_predictions(congress_pred)\n",
        "bjp_numbers = get_predictions(bjp_pred)\n",
        "print(\"Congress Positive Tweets:\",congress_numbers)\n",
        "print(\"BJP Positive Tweets:\",bjp_numbers)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}